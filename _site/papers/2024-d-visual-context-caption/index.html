<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8">
    <meta name="citation_title" content="視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法" />

    <meta name="citation_author" content="前田, 航希" />

    <meta name="citation_author" content="栗田, 修平" />

    <meta name="citation_author" content="宮西, 大樹" />

    <meta name="citation_author" content="岡崎, 直観" />

    <meta name="citation_conference_title" content="言語処理学会第30回年次大会 (NLP2024)" />
    <meta name="citation_date" content="2024" />
    <meta name="citation_publication_date" content="2024/03/01" />

    <meta name="citation_firstpage" content="1996" />


    <meta name="citation_lastpage" content="2001" />

    <meta name="citation_abstract_html_url" content="/papers/2024-d-visual-context-caption/">

    <meta name="citation_pdf_url" content="/assets/papers/2024_d_visual_context_caption.pdf" />

    <title>視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="stylesheet" href="/style.css">
    <script>
      var shiftWindow = function() { scrollBy(0, -50) };
      window.addEventListener("hashchange", shiftWindow);
      function load() { if (window.location.hash) shiftWindow(); }
    </script>
</head>
<body>
    <div class="container">
        <header class="blog-header">
            <h1>Paper Detail</h1>
            <nav class="site-nav">
                <a href="/">Home</a>
                <a href="/papers.html" class="active">Papers</a>
                <a href="/blog.html">Blog</a>
            </nav>
        </header>

        <div class="paper-meta">
            <h1 class="title">視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法</h1>
            <div class="venue">言語処理学会第30回年次大会 (NLP2024)</div>
            <div class="description">画像キャプション生成の自動評価において、従来手法は画像と生成キャプションの意味的整合性のみを考慮し、文脈情報を無視していた。本研究では、視覚言語モデルを用いて画像の視覚的文脈を考慮した新たな自動評価手法を提案する。提案手法は、画像中の物体間の関係性や空間的配置、シーンの文脈を理解し、それらを評価に反映させることで、人間の評価により近い結果を実現する。実験により、提案手法が既存の評価指標よりも人間の判断との相関が高いことを示した。</div>
            <div class="type">domestic</div>

            <div class="action-buttons">

                <a href="/assets/papers/2024_d_visual_context_caption.pdf" class="pdf-link">
                    <i class="fas fa-file-pdf"></i>
                    PDF
                </a>


                <a href="https://github.com/Silviase/VisCE2" class="code-link">
                    <i class="fas fa-code"></i>
                    Code
                </a>

            </div>

            <pre class="bibtex">@inproceedings{maeda2024visual,
  title={視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法},
  author={前田 航希 and 栗田 修平 and 宮西 大樹 and 岡崎 直観},
  booktitle={言語処理学会第30回年次大会 (NLP2024)},
  pages={1996--2001},
  year={2024},
  address={東京}
}
</pre>
        </div>

        <div class="paper-content"><p><a href="/assets/papers/2024_d_visual_context_caption.pdf">PDF</a></p>
</div>
    </div>

    <footer class="footer">
        <div class="container">
            <p>© 2025 Koki Maeda • Last Updated: March 2025</p>
        </div>
    </footer>
</body>
</html>
