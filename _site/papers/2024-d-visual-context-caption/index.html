<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="icon" href="/assets/favicon.svg" type="image/svg+xml" />
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet" />
<link rel="stylesheet" href="/assets/css/main.css" />
  
<meta name="citation_title" content="視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法" />
 
<meta name="citation_author" content="前田, 航希" />

<meta name="citation_author" content="栗田, 修平" />

<meta name="citation_author" content="宮西, 大樹" />

<meta name="citation_author" content="岡崎, 直観" />
  
<meta name="citation_conference_title" content="言語処理学会第30回年次大会 (NLP2024)" />
  
<meta name="citation_publication_date" content="2024/03/01" />
<meta name="citation_date" content="2024" />
 
<meta name="citation_firstpage" content="1996" />
 
<meta name="citation_lastpage" content="2001" />
 
<meta name="citation_abstract_html_url" content="https://silviase.github.io/papers/2024-d-visual-context-caption/" />
  
<meta name="citation_pdf_url" content="https://silviase.github.io/assets/papers/2024_d_visual_context_caption.pdf" />

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法 | Koki Maeda</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法" />
<meta name="author" content="前田, 航希" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="画像キャプション生成の自動評価において、従来手法は画像と生成キャプションの意味的整合性のみを考慮し、文脈情報を無視していた。本研究では、視覚言語モデルを用いて画像の視覚的文脈を考慮した新たな自動評価手法を提案する。提案手法は、画像中の物体間の関係性や空間的配置、シーンの文脈を理解し、それらを評価に反映させることで、人間の評価により近い結果を実現する。実験により、提案手法が既存の評価指標よりも人間の判断との相関が高いことを示した。" />
<meta property="og:description" content="画像キャプション生成の自動評価において、従来手法は画像と生成キャプションの意味的整合性のみを考慮し、文脈情報を無視していた。本研究では、視覚言語モデルを用いて画像の視覚的文脈を考慮した新たな自動評価手法を提案する。提案手法は、画像中の物体間の関係性や空間的配置、シーンの文脈を理解し、それらを評価に反映させることで、人間の評価により近い結果を実現する。実験により、提案手法が既存の評価指標よりも人間の判断との相関が高いことを示した。" />
<link rel="canonical" href="https://silviase.github.io/papers/2024-d-visual-context-caption/" />
<meta property="og:url" content="https://silviase.github.io/papers/2024-d-visual-context-caption/" />
<meta property="og:site_name" content="Koki Maeda" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-03-01T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"前田, 航希"},"dateModified":"2024-03-01T00:00:00+09:00","datePublished":"2024-03-01T00:00:00+09:00","description":"画像キャプション生成の自動評価において、従来手法は画像と生成キャプションの意味的整合性のみを考慮し、文脈情報を無視していた。本研究では、視覚言語モデルを用いて画像の視覚的文脈を考慮した新たな自動評価手法を提案する。提案手法は、画像中の物体間の関係性や空間的配置、シーンの文脈を理解し、それらを評価に反映させることで、人間の評価により近い結果を実現する。実験により、提案手法が既存の評価指標よりも人間の判断との相関が高いことを示した。","headline":"視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法","mainEntityOfPage":{"@type":"WebPage","@id":"https://silviase.github.io/papers/2024-d-visual-context-caption/"},"url":"https://silviase.github.io/papers/2024-d-visual-context-caption/"}</script>
<!-- End Jekyll SEO tag -->


  </head>
  <body class="layout-paper">
    <div class="page-shell">
      <header class="site-header">
  <div class="container">
    <div class="site-branding">
      <a class="site-title" href="/">Koki Maeda</a>
      
      <p class="site-tagline">Doctoral student exploring multimodal vision-and-language systems, evaluation metrics, and context-aware captioning.</p>
      
    </div>
    <nav class="site-nav">
           
      <a href="/" class="">Home</a>
         
      <a href="/cv/" class="">CV</a>
         
      <a href="/papers/" class="active">Papers</a>
         
      <a href="/blog/" class="">Blog</a>
      
    </nav>
  </div>
</header>

      <main class="site-main"><article class="paper-detail">
  <div class="container">
    <nav class="back-nav">
      <a href="/papers/">← Back to Papers</a>
    </nav>
    <header class="paper-header">
      <h1 class="paper-title">視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法</h1>
      
      <p class="paper-authors">
        
        <span class="paper-author">前田, 航希</span>,  
        <span class="paper-author">栗田, 修平</span>,  
        <span class="paper-author">宮西, 大樹</span>,  
        <span class="paper-author">岡崎, 直観</span> 
      </p>
      
      <p class="paper-publication">
         言語処理学会第30回年次大会 (NLP2024)  
        · March 2024 
      </p>
      
      <p class="paper-summary">画像キャプション生成の自動評価において、従来手法は画像と生成キャプションの意味的整合性のみを考慮し、文脈情報を無視していた。本研究では、視覚言語モデルを用いて画像の視覚的文脈を考慮した新たな自動評価手法を提案する。提案手法は、画像中の物体間の関係性や空間的配置、シーンの文脈を理解し、それらを評価に反映させることで、人間の評価により近い結果を実現する。実験により、提案手法が既存の評価指標よりも人間の判断との相関が高いことを示した。</p>
      
      <div class="paper-actions">
           
        <a class="button" href="/assets/papers/2024_d_visual_context_caption.pdf" target="_blank" rel="noopener">
          <span aria-hidden="true">📄</span> PDF
        </a>
         
        <a class="button" href="https://github.com/Silviase/VisCE2" target="_blank" rel="noopener">
          <span aria-hidden="true">💻</span> Code
        </a>
        
      </div>
    </header>

    
    <section class="paper-bibtex">
      <h2>BibTeX</h2>
      <pre><code>@inproceedings{maeda2024visual,
  title={視覚的文脈を利用した視覚言語モデルによる画像キャプション生成自動評価手法},
  author={前田 航希 and 栗田 修平 and 宮西 大樹 and 岡崎 直観},
  booktitle={言語処理学会第30回年次大会 (NLP2024)},
  pages={1996--2001},
  year={2024},
  address={東京}
}</code></pre>
    </section>
    

    <section class="paper-content"><p><a href="/assets/papers/2024_d_visual_context_caption.pdf">PDF</a></p>
</section>
  </div>
</article>
</main>
      <footer class="site-footer">
  <div class="container">
    <p>© 2025 Koki Maeda · Built with Jekyll</p>
  </div>
</footer>

    </div>
    <script src="/assets/js/site.js"></script>
    
  </body>
</html>
