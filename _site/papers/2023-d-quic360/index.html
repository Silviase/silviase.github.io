<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="icon" href="/assets/favicon.svg" type="image/svg+xml" />
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet" />
<link rel="stylesheet" href="/assets/css/main.css" />
  
<meta name="citation_title" content="QuIC-360◦: 360◦ 画像に対するクエリ指向画像説明文生成のためのデータセット構築" />
 
<meta name="citation_author" content="前田, 航希" />

<meta name="citation_author" content="栗田, 修平" />

<meta name="citation_author" content="宮西, 大樹" />
  
<meta name="citation_conference_title" content="言語処理学会第29回年次大会 (NLP2023)" />
  
<meta name="citation_publication_date" content="2023/03/01" />
<meta name="citation_date" content="2023" />
 
<meta name="citation_firstpage" content="3013" />
 
<meta name="citation_lastpage" content="3018" />
 
<meta name="citation_abstract_html_url" content="https://silviase.github.io/papers/2023-d-quic360/" />
  
<meta name="citation_pdf_url" content="https://silviase.github.io/assets/papers/2023_d_quic360.pdf" />

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>QuIC-360◦: 360◦ 画像に対するクエリ指向画像説明文生成のためのデータセット構築 | Koki Maeda</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="QuIC-360◦: 360◦ 画像に対するクエリ指向画像説明文生成のためのデータセット構築" />
<meta name="author" content="前田, 航希" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="360◦ 画像は一般的な画像と比較して，撮影者による情報の取捨選択が行われないため，多くのコンテクストを同時に含む．既存の画像説明文生成では，コンテクストを画像情報のみから読み取るが，360◦ 画像に対しては，画像に加えて補助的な情報を付加することで，記述するコンテクストを指定することが必要になる．本研究では，画像に加えて言語情報（クエリ）を与えることで説明文生成を制御するクエリ指向説明文生成を提案し，そのためのデータセットとして 5,800 枚の 360◦ 画像と 22,956 文の説明文からなる QuIC-360◦ を構築した．QuIC-360◦ による再学習で，360◦ 画像に対してクエリを用いることで説明文生成の制御性・多様性が高まることが確認された．" />
<meta property="og:description" content="360◦ 画像は一般的な画像と比較して，撮影者による情報の取捨選択が行われないため，多くのコンテクストを同時に含む．既存の画像説明文生成では，コンテクストを画像情報のみから読み取るが，360◦ 画像に対しては，画像に加えて補助的な情報を付加することで，記述するコンテクストを指定することが必要になる．本研究では，画像に加えて言語情報（クエリ）を与えることで説明文生成を制御するクエリ指向説明文生成を提案し，そのためのデータセットとして 5,800 枚の 360◦ 画像と 22,956 文の説明文からなる QuIC-360◦ を構築した．QuIC-360◦ による再学習で，360◦ 画像に対してクエリを用いることで説明文生成の制御性・多様性が高まることが確認された．" />
<link rel="canonical" href="https://silviase.github.io/papers/2023-d-quic360/" />
<meta property="og:url" content="https://silviase.github.io/papers/2023-d-quic360/" />
<meta property="og:site_name" content="Koki Maeda" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-03-01T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="QuIC-360◦: 360◦ 画像に対するクエリ指向画像説明文生成のためのデータセット構築" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"前田, 航希"},"dateModified":"2023-03-01T00:00:00+09:00","datePublished":"2023-03-01T00:00:00+09:00","description":"360◦ 画像は一般的な画像と比較して，撮影者による情報の取捨選択が行われないため，多くのコンテクストを同時に含む．既存の画像説明文生成では，コンテクストを画像情報のみから読み取るが，360◦ 画像に対しては，画像に加えて補助的な情報を付加することで，記述するコンテクストを指定することが必要になる．本研究では，画像に加えて言語情報（クエリ）を与えることで説明文生成を制御するクエリ指向説明文生成を提案し，そのためのデータセットとして 5,800 枚の 360◦ 画像と 22,956 文の説明文からなる QuIC-360◦ を構築した．QuIC-360◦ による再学習で，360◦ 画像に対してクエリを用いることで説明文生成の制御性・多様性が高まることが確認された．","headline":"QuIC-360◦: 360◦ 画像に対するクエリ指向画像説明文生成のためのデータセット構築","mainEntityOfPage":{"@type":"WebPage","@id":"https://silviase.github.io/papers/2023-d-quic360/"},"url":"https://silviase.github.io/papers/2023-d-quic360/"}</script>
<!-- End Jekyll SEO tag -->


  </head>
  <body class="layout-paper">
    <div class="page-shell">
      <header class="site-header">
  <div class="container">
    <div class="site-branding">
      <a class="site-title" href="/">Koki Maeda</a>
      
      <p class="site-tagline">Doctoral student exploring multimodal vision-and-language systems, evaluation metrics, and context-aware captioning.</p>
      
    </div>
    <nav class="site-nav">
           
      <a href="/" class="">Home</a>
         
      <a href="/cv/" class="">CV</a>
         
      <a href="/papers/" class="active">Papers</a>
         
      <a href="/blog/" class="">Blog</a>
      
    </nav>
  </div>
</header>

      <main class="site-main"><article class="paper-detail">
  <div class="container">
    <nav class="back-nav">
      <a href="/papers/">← Back to Papers</a>
    </nav>
    <header class="paper-header">
      <h1 class="paper-title">QuIC-360◦: 360◦ 画像に対するクエリ指向画像説明文生成のためのデータセット構築</h1>
      
      <p class="paper-authors">
        
        <span class="paper-author">前田, 航希</span>,  
        <span class="paper-author">栗田, 修平</span>,  
        <span class="paper-author">宮西, 大樹</span> 
      </p>
      
      <p class="paper-publication">
         言語処理学会第29回年次大会 (NLP2023)  
        · March 2023 
      </p>
      
      <p class="paper-summary">360◦ 画像は一般的な画像と比較して，撮影者による情報の取捨選択が行われないため，多くのコンテクストを同時に含む．既存の画像説明文生成では，コンテクストを画像情報のみから読み取るが，360◦ 画像に対しては，画像に加えて補助的な情報を付加することで，記述するコンテクストを指定することが必要になる．本研究では，画像に加えて言語情報（クエリ）を与えることで説明文生成を制御するクエリ指向説明文生成を提案し，そのためのデータセットとして 5,800 枚の 360◦ 画像と 22,956 文の説明文からなる QuIC-360◦ を構築した．QuIC-360◦ による再学習で，360◦ 画像に対してクエリを用いることで説明文生成の制御性・多様性が高まることが確認された．</p>
      
      <div class="paper-actions">
           
        <a class="button" href="/assets/papers/2023_d_quic360.pdf" target="_blank" rel="noopener">
          <span aria-hidden="true">📄</span> PDF
        </a>
         
        <a class="button" href="https://github.com/Silviase/QuIC-360" target="_blank" rel="noopener">
          <span aria-hidden="true">💻</span> Code
        </a>
        
      </div>
    </header>

    
    <section class="paper-bibtex">
      <h2>BibTeX</h2>
      <pre><code>@inproceedings{maeda2023quic360,
  title={QuIC-360◦: 360◦ 画像に対するクエリ指向画像説明文生成のためのデータセット構築},
  author={前田 航希 and 栗田 修平 and 宮西 大樹},
  booktitle={言語処理学会第29回年次大会 (NLP2023)},
  pages={3013--3018},
  year={2023},
  address={東京}
}</code></pre>
    </section>
    

    <section class="paper-content"><p><a href="/assets/papers/2023_d_quic360.pdf">PDF</a></p>
</section>
  </div>
</article>
</main>
      <footer class="site-footer">
  <div class="container">
    <p>© 2025 Koki Maeda · Built with Jekyll</p>
  </div>
</footer>

    </div>
    <script src="/assets/js/site.js"></script>
    
  </body>
</html>
